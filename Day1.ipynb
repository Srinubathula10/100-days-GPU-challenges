{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfvb3RgiANJZ",
        "outputId": "ac32fe64-fbba-4bfb-c3d3-30d275a241cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_add.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile vector_add.cu\n",
        "#include <iostream>\n",
        "#include <cstdio> // Required for printf\n",
        "\n",
        "__global__ void vectorAdd(const float* A, const float* B, float* C, int N) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < N) {\n",
        "        C[i] = A[i] + B[i];\n",
        "        printf(\"Thread %d processing index %d\\n\", threadIdx.x, i); // Added printf\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 10;\n",
        "    float A[N], B[N], C[N];\n",
        "\n",
        "    // Initialize host arrays (optional, but good for testing)\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        A[i] = i;\n",
        "        B[i] = i * 2;\n",
        "    }\n",
        "\n",
        "    float *d_a, *d_b,*d_c;\n",
        "    cudaMalloc(&d_a,N*sizeof(float));\n",
        "    cudaMalloc(&d_b,N*sizeof(float));\n",
        "    cudaMalloc(&d_c,N*sizeof(float));\n",
        "    cudaMemcpy(d_a,A,N*sizeof(float),cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b,B,N*sizeof(float),cudaMemcpyHostToDevice);\n",
        "    int blocksize=256;\n",
        "    int gridsize=ceil((float)N/blocksize); // Cast N to float for ceil\n",
        "    vectorAdd<<<gridsize,blocksize>>>(d_a,d_b,d_c,N);\n",
        "\n",
        "    // Add synchronization to ensure all printf output is flushed\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaMemcpy(C,d_c,N*sizeof(float),cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print results (optional, but good for testing)\n",
        "    printf(\"Results:\\n\");\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        printf(\"C[%d] = %f\\n\", i, C[i]);\n",
        "    }\n",
        "\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0; // Added return statement\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile with the specified architecture\n",
        "!nvcc vector_add.cu -o vector_add -gencode arch=compute_75,code=sm_75\n",
        "\n",
        "# Run the executable\n",
        "!./vector_add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsTFyY_5BgpD",
        "outputId": "efa6625d-b0a9-49b1-f016-7115c235bb4d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            "C[0] = 0.000000\n",
            "C[1] = 0.000000\n",
            "C[2] = 0.000000\n",
            "C[3] = 0.000000\n",
            "C[4] = 0.000000\n",
            "C[5] = 0.000000\n",
            "C[6] = 0.000000\n",
            "C[7] = 0.000000\n",
            "C[8] = 0.000000\n",
            "C[9] = 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s_n0M-oDEpX7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}